---
title: "A Functional Approach to (Parallelised) Monte Carlo Simulation"
subtitle: "Advanced R for Econometricians"
type: "Final Project"
author: "Alexander Langnau, Öcal Kaptan, Sunyoung Ji"
discipline: "M.Sc. Econometircs"
date: "today"
studid: "232907, 230914, 229979"
supervisor: "Prof. Dr. Christoph Hanck"
secondsupervisor: "M.Sc. Martin C. Arnold, M.Sc. Jens Klenke"
ssemester: "1"
estdegree_emester: "Summer Term 2022"
deadline: "09. 09. 2022"
output:
  pdf_document:
    keep_tex: yes
    template: template.tex
    fig_caption: yes
    citation_package: biblatex
    number_sections: true
toc: true
lot: true
lof: true
graphics: true
biblio-title: References
fontsize: 11pt
geometry: lmargin=2.5cm,rmargin=2.5cm,tmargin=2.5cm,bmargin=2.5cm
biblio-files: references.bib
classoption: a4paper
language: english
---

<!-- % Template Version 1.2 -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(123)
```

```{r library, include=FALSE}
require(utils)
library(tidyverse)
library(purrr)
library(parallel)
library(furrr)
```

# Introduction

Monte Carlo, named after a casino in Monaco, simulates complex probabilistic events using simple random events, such as the tossing of a pair of dice to simulate the casino’s overall business model. In Monte Carlo computing, a pseudo-random number generator is repeatedly called which returns a real number in [0, 1], and the results are used to generate a distribution of samples that is a fair representation of the target probability distribution under study. [@Barbu, Adrian_2022]
Monte Carlo Method is combined with programming in modern research and contributes to various studies.

Monte Carlo simulations are and will stay an important method in the tool box of any
econometrician, statistican or data scientist. Since these simulations  may be needed on a regular basis or are run over a complex set of functions and parameters, its time well spend to implement some
tools, that allow the user to easily create a variety of different Monte Carlo studies. 

This paper was the final project of the course "Advanced R for econometricians" at the chair of econometrics at university Duisburg Essen. The goal is to use a functional programming aproach to create a collection of different wrapper functions in R, that 
- providing a convenient interface for Monte Carlo Simulations
- create a paramter grid
- iterate homogenous function calls over the parameter grid
- provides an informative summary of the simulation results
- can be visualized by ggplot-methods
- offers the possibility to use parallelised processing (using `furrr` package)

A functional programming approach is well suited to implement the different steps.
The structure of this paper underlying code in general follows this approach:

In chapter xyz we introduce different functions, that each specifically solve the task of the bullet points mentioned above. In the beginning we´ll underline the motivation and problem behind each function and showcase the code.

At the end of each section we provide a minimal working example, that illustrates the function and its output. We tried to implement in a way, that the function works for as much cases, as possible. If there are some restrictions regarding the usage of those functions, we´ll briefly discuss them as well.

# Preprocess / Helper functions

## Function for creating grid  

In order to efficiently run a Monte Carlo simulation, we first need to specify for which set of parameters we want to run the simulation process. In case more than one variable is defined, it reasonable to create a parameter grid for each different combination of parameters.


                      
  
```{r create grid}
create_grid <- function(parameters, nrep){
  input <- parameters
  storage <- list()
  name_vec <- c()
  
  for(i in 1:length(input)){ #1:3
    a <- as.numeric(input[[i]][[2]])
    b <- as.numeric(input[[i]][[3]])
    c <- as.numeric(input[[i]][[4]])
    output <- seq(from=a, to=b, by=c)
    storage[[i]] <-  output
    name_vec[i] <- input[[i]][[1]]
  }
  
  grid <- expand_grid(unlist(storage[1])
                      , unlist(storage[2])
                      , unlist(storage[3])
                      , unlist(storage[4])
                      , unlist(storage[5])
                      , c(1:nrep))
  
  names(grid) <- c(name_vec, "rep")
  
  return(grid)
}
```

`create_grid` is the function hat creates a parameter grid with all permutations of the given parameters. The user has to input the parameters as a list, thats specified in the following way: 



`parameter_list` <- `list(c("variable name 1", from, to, by)`
                      `,c("variable name 2", from, to, by)`
                      `,c("variable name 3", from, to, by)`
                      `,c("variable name 4", from, to, by))`

                      
The function works with a minimum of 1 and a maximum of 4 variables. The structure of the remaining arguments is kept similar to the way the way R´s build in function`seq()` is specified: The first argument after the variable name defines the start of the sequence, the second one the end and the last one the steps, by which each variable specified for the parameter grid.

It would be fairly easy to adapt this helper function for more parameters, but it is assumed, that a parameter grid with up to 4 parameters offers enough complexity for the simulation. The function basically takes the infromation of the input parameter list and creates a parameter grid with 
`tidyr::expand_grid()`. The function also makes sure that the columns are named after the correct variable and also creates a different row for each number repetition, that the user specified in the second argument of `create_grid()`, namely `nrep`.

Following is a demonstration of how the input and output of this function looks like:
                      

`create_grid()` Example:
```{r testing create_grid}

#four parameters 
param_list0 <- list(c("n", 10, 20, 10)
                    ,c("mu", 0, 0.5, 0.25)
                    ,c("sd", 0, 0.3, 0.1)
                    ,c("gender", 0, 1, 1))

head(create_grid(param_list0, nrep=3), n=20)

```



## Data generation function

Our second helper function called `data_generation()` uses the parameter grid (`grid`) and a user defined function for data generation (specified as input named `simulation`), f.e. `rnorm()`, `runif()` or `rpois()` to create data under the exact parameters specified in the grid. The draw of data points for each row of the parameter grid gets stored as a seperate element in a list. 

Depenend on how many parameters were specified by the user, different functions of the `purrr`-package are are used, to run the specified function over the parameter grid. In case the user is looking to improve performance, a way of choosing a parallelised processing function of the `furrr`-package is offered.

- `map()` is used for one parameter and `future_map()` function is used  for parallel process instead of `map()` function. Same for  other `map()` functions as seen below.
- `map2()` is used for two parameters and  `future_map2()` function is used  for parallel process instead of `map2()` function.
- `pmap()` is used for three or more parameters and `future_pmap()` function is used  for parallel process instead of `pmap()` function.

 `options = furrr_options(seed = TRUE)` is used for reproducible random number generation process. This argument
takes control of the RNG process for paralleization. It generates the same numbers for the given seed. More details can be found by running the command
`?furrr_options` in RStudio.


```{r data generation and parallel process}
data_generation <- function(simulation, grid){ #this is for use inside the function
  
  if(ncol(grid)==2){
    var1 <- c(unlist(grid[,1]))
    if(cores>1){
      data <- future_map(var1, simulation,.options = furrr_options(seed = TRUE))
    }else{
      data <- map(var1, simulation)
    }
  }
  
  if(ncol(grid)==3){
    var1 <- c(unlist(grid[,1]))
    var2 <- c(unlist(grid[,2]))
    if(cores>1){
      data <- future_map2(var1, var2, simulation,.options = furrr_options(seed = TRUE))
    } else{
      data <- map2(var1, var2, simulation)
    }
  } 
  
  if(ncol(grid)==4){ #need to implement more than 3?!
    var1 <- c(unlist(grid[,1]))
    var2 <- c(unlist(grid[,2]))
    var3 <- c(unlist(grid[,3]))
    list1 <- list(var1,var2,var3)
    if(cores>1){
      data <- future_pmap(list1, .f=simulation,.options = furrr_options(seed = TRUE))
    }else{
      data <- pmap(list1, .f=simulation)
    }
  }
  
  return(data)
}
```




Following, we´d like to demonstrate the data genaration function with a simple example using the normal distribution (`rpois()`)  as the underlying data generating process. At this point we waive running an example without parallel process of our data generating function, since the output wouldn't look different compared to the previous example. At a later point in the paper we´ll showcase the difference in computation time for the different functions.


`data_generation()` Example:
```{r test data_generation()}
cores <- 1
#param_list1 <- list(c("n", 10, 20, 10))

param_list2 <- list(c("n", 10, 20, 10)
                  ,c("lambda", 0.5, 1, 0.5))
#create_grid(param_list1, nrep=10)
#create_grid(param_list1, nrep=1)

'grid1 <- create_grid(param_list1, nrep=3)
tail(data_generation(simulation=rnorm, grid=grid1),1)'

grid2 <- create_grid(param_list2, nrep=1)
sim1 <- data_generation(simulation=rpois, grid=grid2)

grid2
str(sim1)
sim1
 
```

We see a list containg one variable for each row of the parameter grid, where all the generated data points are stored. For example, the last row (stored under `sim1$n4`) specified n = 10 draws from the normal distribution with $\lambda = 1$. Since we set `nrep = 1` in order to save space, the draw only happened once.

The format list offers alot of flexibility, but is not very overseeable. At this point we can use the raw data to run summary statistics on, which we´ll do in the next passage.





```{r, dg application}
# Application to Uniform distribution
param_list_runif <- list(c("n", 10, 30, 10)
                         ,c("min", 0, 0, 0)
                         ,c("max", 1, 1, 0))


grid_unif <- create_grid(param_list_runif, nrep=3)
tail(data_generation(simulation=runif, grid=grid_unif),1)

# Application to Poisson distribution

param_list_rpois <- list(c("n", 10, 30, 10)
                         , c("lambda", 0, 10, 1))

grid_pois <- create_grid(param_list_rpois, nrep=3)
tail(grid_pois,2) # nrow(grid_pois) = 99
tail(data_generation(simulation=rpois, grid=grid_pois),1)
```

## Summary function

Using the tools we showed before the user is able to generate the *raw* data from an underlying distribution of his choice. The next step is to introduce a way of applying a defined summary statistics onto that data, which we realised using the function called  `summary_function()`.

This function basically just applys the user defined summary function (under the input `sum_fun`) onto the raw data using a `sapply()`-loop. The results gets stored in a nrow(grid ) x 1 dimensional matrix, which will be combined with the parameter grid in the next step, in order to correctly allocate each result to the related set of parameters.

```{r summary}
#summary function for one input
summary_function <- function(sum_fun, data_input){
  
  count <- length(data_input)
  summary_matrix <- matrix(nrow=count, ncol=1)
  
  for(i in 1:count){
    input <- list(data_input[[i]])
    output <- sapply(sum_fun, do.call, input)
    summary_matrix[i] <- output
  }
  #output <- as.data.frame(summary_matrix)
  #names(output) <- sum_fun
  colnames(summary_matrix) <- sum_fun
  return(summary_matrix)
}
```

The example to demonstrate this function uses rnorm()-function as underlying DGB, where we specified a parameter grid over three parameters (n, $\mu$ and the standard deviation).


`summary_function` Example:
```{r summary test}
param_list3 <- list(c("n", 10, 20, 10)
                    ,c("mu", 1, 2, 0.25)
                    ,c("sd", 0.5, 1, 0.1))

grid_test <- create_grid(param_list3, nrep=3)
test_data <- data_generation(simulation=rnorm, grid=grid_test)
summary_data <- summary_function(sum_fun=list("mean"), data_input=test_data)
head(summary_data)
```

## Summary array funcation

Even tough we specified a fairly small parameter grid in the example above, our simulation consisted retuned 180 summarised data points for the specified simulation. In the main_function() the results from the previous step get merged with the parameter grid into one data frame. This way of storing the data allows the user to apply further data wrangling processes, but is not suitable for printing the output in a tidy and clear way. A multt-dimensional array is better suited for this case.

The function `create_array_function()` takes all relevant data from the steps before (parameter grid and the results of the Monte Carlo simulation) and transforms it into an array with the correct dimensions. 


```{r, array}
create_array_function <- function(comb, parameters, nrep){
  storage <- list()
  name_vec <- c()
  
  for(i in 1:length(parameters)){ 
    #this creates the sequences of parameters
    a <- as.numeric(parameters[[i]][[2]])
    b <- as.numeric(parameters[[i]][[3]])
    c <- as.numeric(parameters[[i]][[4]])
    output <- seq(from=a, to=b, by=c)
    storage[[i]] <-  output
    name_vec[i] <- parameters[[i]][[1]] 
    #this just stores the names of the variables
  }
  
  
  matrix.numeration <-  paste("rep","=", 1:nrep, sep = "")
  
  if(length(parameters)==1){
    comb_ordered <-  comb %>% arrange(comb[,2])
    seq1 <- c(unlist(storage[1]))
    
    row.names <- paste(name_vec[1],"=",seq1, sep = "")
    
    dimension_array <- c(length(seq1), nrep)
    dim_names_list <- list(row.names, matrix.numeration)
  }
  
  if(length(parameters)==2){
    comb_ordered <-  comb %>% arrange(comb[,2])  %>% arrange(comb[,3])
    seq1 <- c(unlist(storage[1]))
    seq2 <- c(unlist(storage[2]))
    
    row.names <- paste(name_vec[1],"=",seq1, sep = "")
    column.names <-  paste(name_vec[2],"=",seq2, sep = "")
    
    dimension_array <- c(length(seq1), length(seq2), nrep)
    dim_names_list <- list(row.names, column.names, matrix.numeration)
  }
  
  if(length(parameters)==3){
    comb_ordered <-  comb %>% arrange(comb[,2])  %>% 
      arrange(comb[,3]) %>% arrange(comb[,4]) 
    seq1 <- c(unlist(storage[1]))
    seq2 <- c(unlist(storage[2]))
    seq3 <- c(unlist(storage[3]))
    
    row.names <- paste(name_vec[1],"=",seq1, sep = "")
    column.names <-  paste(name_vec[2],"=",seq2, sep = "")
    matrix.names1 <-  paste(name_vec[3],"=",seq3, sep = "")
    
    dimension_array <- c(length(seq1), length(seq2), length(seq3), nrep)
    dim_names_list <- list(row.names, column.names, 
                           matrix.names1, matrix.numeration)
    
  }
  
  
  array1 <- array(comb_ordered[,ncol(comb)] 
                  #change to automatically adjust dim
                  , dim = dimension_array
                  , dim_names_list)
  return(array1)
}

```

In order to test this function, we need to set up an altered version of the main_function(), that is introduced in the next passage.


`create_array_function` Example:
```{r, array ex}

# PREP TEST `create_array_function`
main_function_array_test <-  function(parameters #list of parameters
                                      , nrep #number of repetitions
                                      , simulation #data genereation
                                      , sum_fun){ #summary statistics
  
  grid <- create_grid(parameters, nrep) #Step 1: create grid
  raw_data <- data_generation(simulation, grid) #Step 2: simlate data
  summary <- summary_function(sum_fun, data_input=raw_data) #Step 3: Summary statistics
  comb <- cbind(grid, summary) #Step 4: Combine resuluts with parameters
  array_1 <- create_array_function(comb, parameters, nrep) #Step 5: Create array
  
  return(comb)
}

param_list3x <- list(c("n", 10, 20, 10)
                     ,c("mu", 0, 5, 1)
                     ,c("sd", 0, 3, 1))

comb1 <- main_function_array_test(parameters=param_list3x
                                  , nrep = 3
                                  , simulation = rnorm
                                  , sum_fun="mean")

comb1

create_array_function(comb=comb1, parameters=param_list3x, nrep=3)
```

We see, that an array with the right dimensions is created.


## Average function

```{r}

average_function <- function(grid_for_avg, summary, nrep){
  grid_for_avg <- grid_for_avg[-ncol(grid_for_avg)] #remove column for reps
  n_rows <- nrow(grid_for_avg)
  n_col <- ncol(grid_for_avg)
  
  for(i in 1:n_rows){
    start <- 1 + (i-1)*nrep
    end <- i*nrep
    grid_for_avg[i, n_col+1] <- mean(summary[start:end, ])
  }
  
  grid_plus_mc <- data.frame(grid_for_avg)
  
  colnames(grid_plus_mc)[n_col+1] <- "avg"
  
  return(grid_plus_mc)
  
}
```



## Output Function

 Goal is to create a function, that takes the Monte Carlo simulation results and all parameter input
and converts it onto output format that prints nicely into the console. `Output_function` 
created for this purpose to store simulation results. `array_1`,`average_over_reps`,`parameters`,`cores`,`simulation`,
`nrep`,`cpt`  are used as input parameters in the `output_function`. Except  the parameter `cpt`, other parameters are defined  and explanied before this section. `cpt` parameters will be  explanied in the section `Main Function`. It is basically saving the execution time of the simulation. 
Lets go to  the each code line and explain them briefly.

 Firstly, `out` object is created to store simulation results, averaged results and  summary of the result in list `list()` format. The name `Eco` implemented as a class of the list `out`, since the spesific class had to implemented for the simulation results as a part of the task in visualisation.
 The results from `array_1` saved here as `out$results` also result for `average_over_reps` saved as `out$average`. Next, same class name is assigned to to `out$results` and `out$average`  also default classes of the both list objects kept as a class. The reason is to prevent the future error while using the ggplot2 methods for simulation results. Because ggplot2 methos works only some spesific classses ( data.frame ,etc.). After that the reporting part is created as a report of simulation result by using `cat()` function. At the end function returned to the object `out`. 

```{r echo=TRUE}
output_function <- function(array_1,average_over_reps,parameters,cores,simulation,
                            nrep,cpt){
  
  out <- list()#Create a emptly list to store simulation result and average result.
  class(out) <- "Eco"  #We have to implement a class. I just gave a random name. "Eco"
  out$results <- array_1 # Saved the simulation result
  out$average <- average_over_reps # And this is the result from average function. All the result collected in the list "out"
  #Because output_function will return the list "out".
  
  #To us ggplot function Alex has created a average function that takes average of the simulation results.
  class(out$average) <- c("Eco",class(out$average))#Again, name the class of the average result
  class(out$results) <- c("Eco",class(out$results))#Also same for the simulation result.
  
  if(cores>1){
    parallel = "Multisession"
  } else {       
    parallel = "Sequential"
  }
  #This part is just a report. It will be shown at the end of the simulation result.
  text <-  cat("\n",
           "Repetition(nrep)      : ",nrep,"\n\n",
           "Parallelization Type  : ",parallel,"\n\n",
           "Number of Cores Used in  Parallelization : ",cores," out of",detectCores(),"\n\n",
           "Input Parameters : ",paste(parameters),"\n\n",
           "Simulation Length :",length(array_1),"\n",
           "Minumum :",min(array_1),"\n",
           "Maximum :",max(array_1),"\n",
           "Mean    :", mean(array_1),"\n",
           "Median  :",median(array_1),"\n\n",
           "Execution Time of Monte Carlo Simulation",as.numeric(cpt),"secs \n\n",
           "Name of The Class :",class(out))
  
  return(out)
}

```
Output of  `output_function` will be as same as the `main_function`.That's no further example is needed here. It will be covered in the next topic called "Main function".



## Main Function

The "main_function" is a function that consist of the helper functions that created above. Here, all the helper functions are included and additionaly some commands and functions added to improve the simulation results. Here only additional arguments will be explained, since the helper functions are explained before.

First, `if()&else()` commands are added to check the number of cores are used in the main function is bigger than maximum number of the cores or not.
Logically the computer cannot use the cores that doesn't exist. `max.cores` is a numeric object that stores the maximum number of the cores in the CPU.
By using the function `detectCores()` from  "parallel" packeage ,maximum number of the cores are stored in `max.cores`. The next is to check if the seed is provided by user or not. If the seed is not provided by the user , the function `sample.int()`generates a random number and uses it as a seed for reproducibility of the simulation. After the function `set.seed()` , `Sys.time()`function is implemented to check execution time of the simulation. `startTime` saves the startind time of the simulation ans endTime saves the ending time of the simulation. At the end , `startTime`is subtracted from `endtTime` and `cpt`is created to store execution time. As explained before ,cpt is used in `output_function` as a part of summary. Lastly, `plan()` function is used for the parallelisation to run the methods "sequential" or "multisession". "Sequential" runs the simulation with 1 core which means no parallelisation is used and  "Multisession" runs the simulation in parallel by using the number of cores that provided by user. For more details please  run the command `?future::plan` in RStudio.


```{r}
main_function <-  function(parameters #list of parameters
                           , nrep #number of repetitions
                           , simulation #data genereation
                           , sum_fun #summary statistics
                           ,seed = NULL#Reproducibility
                           ,cores=NULL){
 
    
  #Number of cores
  max.cores <- detectCores()
  if(cores>max.cores){
    stop("Number of Cores cannot be bigger than total number of cores")
  }
  if(!is.null(seed)) {#Reproducibility
    set.seed(seed)}#If seed provided then set.seed takes the number
  else {
    warning("No seed provided!", call. = FALSE)
    seed <- sample.int(10000, 1)#if its not provided then we generate random seed
    set.seed(seed)
    message("Random seed = ", seed, "\n")} 
  
  
  startTime <- Sys.time()#Starting time 
  
  
  
  grid <- create_grid(parameters, nrep) #Step 1: create grid
  
  if(cores > 1){
    plan(multisession,workers = cores)
  } else{
    plan(sequential)
  }
  suppressMessages(raw_data <- data_generation(simulation, grid))
  
  summary <- summary_function(sum_fun, data_input=raw_data) #Step 3: Summary statistics
  
  average_over_reps <- average_function(grid_for_avg=create_grid(parameters, 1), summary, nrep)
  
  comb <- cbind(grid, summary) #Step 4: Combine resuluts with parameters
  
  array_1 <- create_array_function(comb, parameters, nrep) #Step 5: Create array
  
  endTime <- Sys.time()#Endtime
  
  cpt <- endTime - startTime#Execution time
  
  summary_1 <- output_function(array_1,average_over_reps,parameters,cores,simulation,
                           nrep,cpt)
  
return(summary_1)
}

```


Lets test the main function by using `rnorm` Monter Carlo simulation.
```{r, Testing main function}
param_list3x <- list(c("n", 10, 100, 10)
                     ,c("mu", 0, 10, 1)
                     ,c("sd", 0, 5, 1))

test_me <- main_function(parameters=param_list3x
              , nrep = 5
              , simulation = rnorm
              , sum_fun="mean"
              ,seed=123 
              ,cores=1)

```
Here there are simulation results, average of simulation result and a summary about simulation. Now, lets check the `ggplot2` methods for this simulation results. `out$average` is created  for visualisation purpose since working with arrays sometimes are trouble.`Ggplot2` methods can be used without any problem by taking average of the simulation.

Lets try it.
```{r,ggplot2}
ggplot(test_me$average,aes(x=avg,y=n))+geom_line()

```
Also with `facet_grid()` function.
```{r,facet}
ggplot(test_me$average,aes(x=avg))+facet_grid(n~.)+geom_density()

```
As proven above ,the simulation result works well with ggplot2 methods.

# Examples
As an example to Monte Carlo Simulation , `OLS` and `GLS` $beta2$ coeffients are simulated by using parallelisation and also without parallelisation to show execution time of the parallel process.
```{r,ols-gls}
ols_f <- function(n,mu,sd){
  e <- rnorm(n,mu,sd)
  x <- runif(n)
  y <- 0.5*x + e
  ols.hat <- t(x) %*% y / t(x)%*%x
  return("ols"=ols.hat)}

gls_f <- function(n,mu,sd){
  e <- rnorm(n,mu,sd)
  x <- runif(n)
  y <- 0.5*x + e
  v.inv <- diag(1/(1:n))
  c <- chol(v.inv)
  cy <- c %*% y
  cx <- c %*% x
  gls_hat <- t(cx) %*% cy / t(cx)%*%cx
  return("gls"=gls_hat)
  
  param_list <- list(c("n",100,1000,100),c("mu",0,1,0.25),c("sd",1,2,.5))
}
```
As seen as above, simple `OLS` and `GLS` functions are defined to find $beta2$ coefficients and also parameter list defined. Here, the execution time of the  `GLS` function would be much more longer than `OLS` function. That's why parallelisation is used for `GLS`function which is more demanding because of `The Cholesky Decomposition`.

Lets run the simulation for `OLS` function first.
```{r}
ols <- main_function(parameters = param_list,nrep=5,simulation = ols_f,sum_fun="mean",seed=123,cores=1)
ols
```

Now lets run it for `GLS` function with parallelisation and check the execution time.On MacBook Air with 8 cores total execution time is 16.84 seconds.
```{r}
gls <- main_function(parameters = param_list,nrep=5,simulation = gls_f,sum_fun="mean",seed=123,cores=8)
gls
``
Now without parallelisation (with 1 core)

```{r}
gls <- main_function(parameters = param_list,nrep=5,simulation = gls_f,sum_fun="mean",seed=123,cores=1)
gls
``
As seen on the summary part, total execution time is 36.35 seconds which also proves that parallel process works well. 

Now, lets use the simulation results and visualise them by using ggplot2 methods.Here, additionaly `MSE`(Mean Square Error) are calculated for each simulation and saved as `out$average$mse`.

```{r}
gls$average <-  gls$average %>% mutate(mse =(2-avg)^2 )
ols$average <-  ols$average %>% mutate(mse =(2-avg)^2 )

ols$average %>% ggplot(aes(x=avg,y=mu,col="OLS"))+
  facet_grid(n~mean(mse))+geom_line()+
 geom_line(data=gls$average,aes(x=avg,y=mu,col="GLS"))+
  scale_color_manual(name = "Estimation", values = c("OLS" = "blue", "GLS" = "red"))

```

Also density graph of `MSE` for `GLS` and `OLS $beta2$ coefficients.
```{r}
ggplot(ols$average,aes(x=mse,col="OLS"))+facet_grid(n~.)+geom_density()+
  geom_density(data=gls$average,aes(x=avg,col="GLS"))+
  scale_color_manual(name = "Estimation", values = c("OLS" = "blue", "GLS" = "red"))
```




# Conclusion

The above section illustrates the power of our implemented model and gives the fairly easy 
to use tool, that still allows for a variety of different specifications in terms of used parameters,
data generation processes and summary functions. Researchers, who use Monte Carlo studys on a regular basis, may save a lot of time using a tool like this in the long run.

By nature, there may be cases, where our implementation doesnt satisfy the needs of the user to the fullest, but for a wide variety of examples we showed, that it worked well and served the goal that we aimed for. Our functional programming approach allows for easy and flexible adjustments in case the use of our functions should be expanded, f.e. if a grid of more than 3 (or 4?) parameters is needed.

Theoretically, this work could be implemented as an R package to share it with the R community. But since the `MonteCarlo()` function of the `vigniette` package already provides a well working alternative to our
project besides some minor differences, there is currently no need in doing that.



# References

# Contributions













\pagebreak




