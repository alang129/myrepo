---
title: "A Functional Approach to (parallelised) Monte Carlo Simulation"
subtitle: "Advanced R for Econometricians"
type: "Final Project"
author: "Alexander Langnau, Öcal Kaptan, Sunyoung Ji"
discipline: "M.Sc. Econometrics"
date: "today"
studid: "232907, 230914, 229979"
supervisor: "Prof. Dr. Christoph Hanck"
secondsupervisor: "M.Sc. Martin C. Arnold, M.Sc. Jens Klenke"
ssemester: "1"
estdegree_emester: "Summer Term 2022"
deadline: "09. 09. 2022"
output:
  pdf_document:
    keep_tex: yes
    template: template.tex
    fig_caption: yes
    citation_package: biblatex
    number_sections: true
toc: true
lot: true
lof: true
graphics: true
biblio-title: References
fontsize: 11pt
geometry: lmargin=2.5cm,rmargin=2.5cm,tmargin=2.5cm,bmargin=2.5cm
biblio-files: references.bib
classoption: a4paper
language: english
---

<!-- % Template Version 1.2 -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(123)
```

```{r library, include=FALSE}
remove(list = ls())

require(utils)
library(tidyverse)
library(purrr)
library(parallel)
library(furrr)
library(future)
```

# Introduction


The Monte Carlo method is a simulation method for calculating the probabilistic value of the desired function using random numbers. A repeated pseudo-random number generator estimates sample statistics and returns a probability distribution of the sample, representing the parameter(Barbu, 2020). Monte Carlo methods are combined with programming in modern research and contribute to various studies in statistics, economics and many other scientific fields. 
This paper progresses on developing a collection of different wrapper functions to partially automatize the process of running a Monte Carlo simulation. The main function, that combines all the other helper functions, provides a convenient interface for Monte Carlo simulations and allows the user to create a parameter grid and iterate homogeneous function calls over the parameter grid. It also offers informative summary statistics, including visualization with `ggplot2`-methods and an option to use a parallelisation plan utilizing the `furrr` package.
The paper proceeds as follows: Chapter 2 describes pre-processes to establish the Monte Carlo simulation function. The pre-process contains functions to create a parameter grid and the respective data points drawn from a user-defined distribution, along with functions that provide summary statistics. Chapter 3 details the main Monte Carlo simulation function, which consists of the helper functions introduced in chapter 2. Chapter 4 presents specific examples for the simulation process. Finally, chapter 5 summarizes the work presented in this paper. Since the output of the simulation in chapter 4 is quite lengthy, it was moved to the Appendix in order not to overload the structure of the actual paper.






# Pre-process: Creating Helper functions

The pre-process comprises 5 helper functions: `create_grid()`, `data_generation()`, `summary_function()`, `create_array_function()` and `output_function()`. The functions are named in a way that the underlying purpose is directly clear. These functions are the building blocks of the `main_function()`, which takes the user input and runs the Monte Carlo simulation by itself.

## Helper function 1: `create_grid()`

The first helper function introduced is the `create_grid()`-function, which automatically creates a hyper-parameter grid over all permutations specified by the user.
  
  
```{r create grid}
create_grid <- function(parameters, nrep){
  input <- parameters
  storage <- list()
  name_vec <- c()
  
  for(i in 1:length(input)){ #1:3
    a <- as.numeric(input[[i]][[2]])
    b <- as.numeric(input[[i]][[3]])
    c <- as.numeric(input[[i]][[4]])
    output <- seq(from=a, to=b, by=c)
    storage[[i]] <-  output
    name_vec[i] <- input[[i]][[1]]
  }
  
  grid <- expand_grid(unlist(storage[1])
                      , unlist(storage[2])
                      , unlist(storage[3])
                      , unlist(storage[4])
                      , unlist(storage[5])
                      , c(1:nrep))
  
  names(grid) <- c(name_vec, "rep")
  
  return(grid)
}
```

Input for the parameter list has to follow a specific format as shown below:

```
parameter_list <- list(c("variable name 1", from, to, by) 
                      ,c("variable name 2", from, to, by)
                      ,c("variable name 3", from, to, by)
                      ,c("variable name 4", from, to, by))
```

`create_grid()` works with a minimum of 1 and a maximum of 4 variables. The structure of arguments in `parameter_list` is similar to `seq()` in R: Each vector contained in the list needs four arguments specified, that is, the function name, the start of the sequence, the end of the sequence and the steps, by which the interval gets divided. It would be easy to adapt this helper function for more parameters, but it is assumed that a grid with up to 4 parameters offers enough complexity for the simulation. The function basically takes the information of the input parameter list and creates a grid with  `tidyr::expand_grid()`. The argument `nrep` specifies how many repetitions per parameter constellation are created, where a separate row in the parameter grid gets created for each repetition.


**Example to `create_grid()`:**
```{r example create_grid}

#four parameters 
param_list0 <- list(c("n", 10, 20, 10)
                    ,c("mu", 0, 0.5, 0.25)
                    ,c("sd", 0, 0.3, 0.1)
                    ,c("gender", 0, 1, 1))

head(create_grid(param_list0, nrep=3), n=10)


```





## Helper function 2: `data_generation()`

The second helper function called `data_generation()` takes the arguments `grid` and `simulation` as inputs. `simulation` is the argument for the user-defined function for the data generation process, while `grid` is the parameter grid previously created. The user can choose between a variety of probability distributions by entering the name of the function, for example, `rnorm` for the normal distribution or `runif` for the uniform distribution.

The n data points created for each set of parameters are stored as separate elements in a list, since this format is a very flexible way of storing data. 

`data_generation()` chooses relative  mapping function base on specification shown as on the table below:


| Mapping | Mapping with parallelisation | Number of parameters |
| :------: | :------: | :------: |
| `purrr::map()` | `furrrr::future_map()` | $n = 1$ |
| `purrr::map2()` | `furrrr:f:uture_map2()` | $n = 2$ | 
| `purrr::pmap()` | `furrrr::future_pmap()` | $n \geq 3$ | 

`options = furrr_options(seed = TRUE)` is for reproducible random number generation (RNG) processes. This argument takes control of the RNG process for parallelisation and always generates the same numbers according to the given seed. More details can be found by running the command `?furrr_options` in RStudio.


```{r data generation and parallel process}
data_generation <- function(simulation, grid){
  
  if(ncol(grid)==2){
    var1 <- c(unlist(grid[,1]))
    if(cores>1){
      data <- future_map(var1, simulation,
                         .options = furrr_options(seed = TRUE))
    }else{
      data <- map(var1, simulation)
    }
  }
  
  if(ncol(grid)==3){
    var1 <- c(unlist(grid[,1]))
    var2 <- c(unlist(grid[,2]))
    if(cores>1){
      data <- future_map2(var1, var2, simulation,
                          .options = furrr_options(seed = TRUE))
    } else{
      data <- map2(var1, var2, simulation)
    }
  } 
  
  if(ncol(grid)==4){
    var1 <- c(unlist(grid[,1]))
    var2 <- c(unlist(grid[,2]))
    var3 <- c(unlist(grid[,3]))
    list1 <- list(var1,var2,var3)
    if(cores>1){
      data <- future_pmap(list1, .f=simulation,
                          .options = furrr_options(seed = TRUE))
    }else{
      data <- pmap(list1, .f=simulation)
    }
  }
  
  return(data)
}
```

Monte Carlo simulations can become very demanding in terms of computing time. In that case, parallel processing may be used to reduce the time of the simulation. In parallel processes, each process is executed simultaneously but independently. Interconnections are proceeded through communication channel(Czech_2017).

`data_generation()` automatically used the proper function from the `furrrr`-package, if the user specified more than one core. Otherwise, the function will stick to the respective mapping function from the `purrr`-package.


**Example to `data_generation()`:**
The example below demonstrates the data generation process using a Poisson distribution without parallelisation. The advantage in computation time with parallelisation will be discussed in Chapter 3.

```{r test data_generation()}
cores <- 1


param_list2 <- list(c("n", 10, 20, 10)
                  ,c("lambda", 0.5, 1, 0.5))



grid2 <- create_grid(param_list2, nrep=1)
sim1 <- data_generation(simulation=rpois, grid=grid2)


names(sim1) <- c("n=10, lamda = 0.5","n=10, lamda = 1",
                 "n=20, lamda = 0.5","n=20, lamda = 1")
grid2
sim1
 
```

`sim1` contains the generated data by `data_generation()` with `grid2` and Poisson distribution as input.
Below, the second example is demonstrated to showcase the capabilities using a uniform distribution. The user could even define his own function for generating the data and use it for the simulation process. The information stored in the parameter list is used by position, not by variable name. Thats why its important specify any variables in the correct order, that shall be used for the simulation. 

```{r, dg application}
# Application to uniform distribution
param_list_runif <- list(c("n", 10, 30, 10)
                         ,c("min", 0, 0, 0)
                         ,c("max", 2, 2, 0))


grid_unif <- create_grid(param_list_runif, nrep=3)
head(data_generation(simulation=runif, grid=grid_unif),4)

```

As explained before, the data is stored in a list, where data points for each set of parameters are stored under a different variable. The first variable (saved under `$n1`) is based on 10 draws from a uniform distribution with $\mathcal{U}_{[0,2]}$. Each variable in the list relates to a row in the parameter grid.


## Helper function 3: `summary_function()`

So far, the paper explains how to create *raw* data with the functions `create_grid()` and  `data_generation()` based on a chosen probability distribution. This chapter introduces `summary_function()` which applies a user-defined function to calculate a summary statistic on the raw data generated before.
The function uses a `sapply`-loop to apply the user-defined summary function (`sum_fun`) on each element of the list containing the raw data. Any summary may be applied, that returns a singular output value. Results are stored in a `(nrow(grid) X 1)`-dimensional matrix, which is combined with the parameter grid in the next step.


```{r summary_function}

summary_function <- function(sum_fun, data_input){
  
  count <- length(data_input)
  summary_matrix <- matrix(nrow=count, ncol=1)
  
  for(i in 1:count){
    input <- list(data_input[[i]])
    output <- sapply(sum_fun, do.call, input)
    summary_matrix[i] <- output
  }

  colnames(summary_matrix) <- sum_fun
  return(summary_matrix)
}
```

**Example to `summary_function()`:**

For this example, data is generated using the normal distribution, with the respective parameters n, $\mu$ and $\sigma$ specified in the parameter list. The list containing the raw data created by `data_generation()` is stored in the variable `test_data`, which is the data input for `summary_function()`. The arithmetic mean, using base R´s `mean()`-function, is supplied as the second input to calculate the average of all the data points created under a unique set of parameters. The output relates exactly to each row of the used parameter grid. Later, these summary statistics are merged with the parameter grid into a data frame.


```{r summary test}

param_list3 <- list(c("n", 10, 20, 10)
                    ,c("mu", 1, 2, 0.25)
                    ,c("sd", 0.5, 1, 0.1))

grid_test <- create_grid(param_list3, nrep=3)
test_data <- data_generation(simulation=rnorm, grid=grid_test)
summary_data <- summary_function(sum_fun=list("mean"),
                                 data_input=test_data)

nrow(summary_data)

head(summary_data)
```


## Helper function 4: `create_array_function()`

Even though the example above applies a relatively small parameter grid, the simulation still returns 180 summarize data points. Like explained before, in `main_function()` the results from the previous step get merged with the parameter grid into one data frame. This way of storing the data allows the user to apply further data wrangling processes, but is not the most overseeable way to display the data. A multidimensional array is more suitable for printing the output in a tidy and clear way. `create_array_function()` takes all relevant data from the previous steps and transforms it into an array with the correct dimensions. The function works with up to three variables supplied in the parameter list. Using the number of repetitions as an additional dimension, `create_array_function()` can create up to 4-dimensional arrays. Due to the same reasoning regarding the size of the parameter grid, no further capabilities were implemented beyond this point, since five or more dimensional arrays would be extremely hard to overlook, even tough it would be easy to expand the use for more variables.


```{r, array}
create_array_function <- function(comb, parameters, nrep){
  storage <- list()
  name_vec <- c()
  
  for(i in 1:length(parameters)){ 
    a <- as.numeric(parameters[[i]][[2]])
    b <- as.numeric(parameters[[i]][[3]])
    c <- as.numeric(parameters[[i]][[4]])
    output <- seq(from=a, to=b, by=c)
    storage[[i]] <-  output
    name_vec[i] <- parameters[[i]][[1]] 
  }
  
  
  matrix.numeration <-  paste("rep","=", 1:nrep, sep = "")
  
  if(length(parameters)==1){ #for 1 variable
    comb_ordered <-  comb %>% arrange(comb[,2])
    seq1 <- c(unlist(storage[1]))
    
    row.names <- paste(name_vec[1],"=",seq1, sep = "")
    
    dimension_array <- c(length(seq1), nrep)
    dim_names_list <- list(row.names, matrix.numeration)
  }
  
  if(length(parameters)==2){ #for 2 variables
    comb_ordered <-  comb %>% arrange(comb[,2])  %>% arrange(comb[,3])
    seq1 <- c(unlist(storage[1]))
    seq2 <- c(unlist(storage[2]))
    
    row.names <- paste(name_vec[1],"=",seq1, sep = "")
    column.names <-  paste(name_vec[2],"=",seq2, sep = "")
    
    dimension_array <- c(length(seq1), length(seq2), nrep)
    dim_names_list <- list(row.names, column.names, matrix.numeration)
  }
  
  if(length(parameters)==3){ #for 3 variable
    comb_ordered <-  comb %>% arrange(comb[,2])  %>% 
      arrange(comb[,3]) %>% arrange(comb[,4]) 
    seq1 <- c(unlist(storage[1]))
    seq2 <- c(unlist(storage[2]))
    seq3 <- c(unlist(storage[3]))
    
    row.names <- paste(name_vec[1],"=",seq1, sep = "")
    column.names <-  paste(name_vec[2],"=",seq2, sep = "")
    matrix.names1 <-  paste(name_vec[3],"=",seq3, sep = "")
    
    dimension_array <- c(length(seq1), length(seq2), length(seq3), nrep)
    dim_names_list <- list(row.names, column.names, 
                           matrix.names1, matrix.numeration)
    
  }
  
  
  array1 <- array(comb_ordered[,ncol(comb)] 
                  , dim = dimension_array
                  , dim_names_list)
  return(array1)
}

```

In order to test `create_array_function()`, we need to set up an altered version of `main_function()`. The `main_function()` will be discussed in the next chapter. Also, a slightly modified version of the example using `rnorm` is used, where the parameter grid spans over a larger sequence, to demonstrate, that `create_array_function()` also works for a complex parameter grid.


  
 

 
**Example to `create_array_function()` :**
```{r, array ex}

# PREP TEST `create_array_function`
main_function_array_test <-  function(parameters #list of parameters
                                      , nrep #number of repetitions
                                      , simulation #data genereation
                                      , sum_fun){ #summary statistics
  
  grid <- create_grid(parameters, nrep) #Step 1: create grid
  raw_data <- data_generation(simulation, grid) #Step 2: simlate data
  summary <- summary_function(sum_fun, data_input=raw_data) #Step 3: Summary statistics
  comb <- cbind(grid, summary) #Step 4: Combine resuluts with parameters
 
  return(comb)
}





param_list3x <- list(c("n", 10, 30, 10)
                     ,c("mu", 0, 6, 1)
                     ,c("sd", 1, 2, 1))

comb1 <- main_function_array_test(parameters=param_list3x
                                  , nrep = 2
                                  , simulation = rnorm
                                  , sum_fun="mean")

array_test <- create_array_function(comb=comb1,
                                    parameters=param_list3x, nrep=2)

array_test
```

Under these specifications, the data was transformed into a 4-dimensional array. Sample size n and the mean $\mu$ are the variables at the side of each row and column. Also, it was specified that two repetitions are done for each set of parameters, while a range of two values ($\sigma = \{1, 2\}$) was given for the standard deviation. The output contains the correct amount of tables, namely two repetitions for $\sigma = 1$ and two repetitions for $\sigma = 2$. This output style allows the user to easily oversee a wide variety of different parameter constellations.



## Helper function 5: `average_function()`

The example above used only two repetitions for each parameter constellation to keep the output simple. However, in practice the user would probably repeat the simulations over a higher number of repetitions, which would also drastically increase the size of the array. It may be of interest to see the average over all repetitions, in order to get a more compact output. `average_function()` calculates the average over all repetitions and stores the results in an array with a dimension, that is reduced by one, since the dimension for repetitions is not relevant anymore. At this point no further example is demonstrated for this function, because the output would look similar to the array before. But the final simulation will include the averaged simulation results, that are created the help of this function.


```{r}

average_function <- function(grid_for_avg, summary, nrep){
  grid_for_avg <- grid_for_avg[-ncol(grid_for_avg)] #remove column for reps
  n_rows <- nrow(grid_for_avg)
  n_col <- ncol(grid_for_avg)
  
  for(i in 1:n_rows){
    start <- 1 + (i-1)*nrep
    end <- i*nrep
    grid_for_avg[i, n_col+1] <- mean(summary[start:end, ])
  }
  
  grid_plus_mc <- data.frame(grid_for_avg)
  
  colnames(grid_plus_mc)[n_col+1] <- "avg"
  
  return(grid_plus_mc)
  
}
```





## Helper function 6: `output_function()`

`output_function()`  is the last part of the pre-process. This function takes results and parameters of the Monte Carlo simulation as inputs and converts them into an tidy output format. Thus, the user can obtain a tidy form of a simulation summary.

`array_1`, `average_over_reps`, `parameters`, `cores`, `simulation`,
`nrep` and `cpt`  are used as input parameters in the `output_function()`.
The variable `cpt` is used to store the execution time of the simulation. The next chapter will discuss this in more detail.

Regarding the structure of `output_function()`, (1) `out` is an empty list for storing simulation results, averaged results and summary. (2) `Eco` is the class name of `out`. The class should be assigned to visualize simulation results with `ggplot2` methods. (3) Results from `array_1` and `average_over_reps` are assigned as `out$results` and `out$average` respectively. (4) These results have classes with their own names: `out$results` and `out$average`, thereby preventing future error when visualizing simulation results with `ggplot2`-methods. `ggplot2`-methods require specific classes, such as `data.frame`. (5) `cat` is useful for producing output in user-defined functions. It converts its arguments to character vectors, concatenates them to a single character vector, appends the given `sep` $=$ `string(s)` to each element and then outputs them (rdocumentation). (6) The neat output is returned at the end.


```{r echo=TRUE}


output_function <- function(array_1,average_over_reps,parameters,cores,simulation,
                            nrep,cpt){
  # (1)
  out <- list() 
  # (2) 
  class(out) <- "Eco" 
  # (3)
  out$results <- array_1 
  out$average <- average_over_reps 
  # (4)
  class(out$average) <- c("Eco",class(out$average))
  class(out$results) <- c("Eco",class(out$results))
  # (5)
  if(cores>1){
    parallel = "Multisession"
  } else {       
    parallel = "Sequential"
  }
  text <-  cat("\n",
           "Repetition(nrep)      : ",nrep,"\n\n",
           "Parallelisation Type  : ",parallel,"\n\n",
           "Number of Cores Used in  Parallelisation : ",cores,
           " out of",detectCores(),"\n\n",
           "Input Parameters : ",paste(parameters),"\n\n",
           "Simulation Length :",length(array_1),"\n",
           "Minumum :",min(array_1),"\n",
           "Maximum :",max(array_1),"\n",
           "Mean    :", mean(array_1),"\n",
           "Median  :",median(array_1),"\n\n",
           "Execution Time of Monte Carlo Simulation",
           as.numeric(cpt),"secs \n\n",
           "Name of The Class :",class(out))
  # (6)
  return(out)
}

```
`output_function()` combines all information relevant for the simulation and stores it into a tidy output format, which gets returned by the `main_function()`, that combines all steps needed for running the simulation. 


\pagebreak
#  Monte Carlo simulation function: `main_function()`

The `main_function()` is built-up by the helper functions introduced in chapter 2 and includes additional arguments to combine different steps of the helper functions. (1) `parameters` is a parameter list, `nrep` is the number of repetitions, `simulation` is a data generation process, `sum_fun` is summary function that the user defines, `seed set` is for reproducibility of the simulation and `cores` is the number of cores, that exist in the CPU. (2) `if and else` commands check how many cores are used in the `main_function()` and whether the user defined variable `cores` exceeds the maximum number of cores contained in the CPU. By using `detectCores()` from the `parallel` package, the maximum number of cores in the CPU is saved under the variable `max.cores`. (3) Setting the seed is an important step to obtain reproducibility. `main_function()` either takes the seed that the user inputs or creates a seed randomly using `sample.int()`,  when no seed is provided. (4) The function `Sys.time()` measures the execution time of the simulation. `startTime` and `endTime` save the simulation's starting time and ending time, respectively. The difference between them is the execution time stored in `cpt`, which is also included in the summary statistics. (5) `plan()` is used to parallelise  the simulation. `plan()` has two arguments, “sequential” or "multisession”. "Sequential" runs non-parallel processing with one core. On the other hand, user can define the number of cores with the "multisession" argument. Lastly, (6) `main_function()` produces tidy summary statistics with `output_function()` in chapter 2.


```{r}
#(1)
main_function <-  function(parameters 
                           , nrep 
                           , simulation 
                           , sum_fun 
                           , seed = NULL
                           , cores=NULL){
 
    
  #(2)
  max.cores <- detectCores()
  if(cores>max.cores){
    stop("Number of Cores cannot be bigger than total number of cores")
  }
  #(3)
  if(!is.null(seed)) {
    set.seed(seed)}
  else {
    warning("No seed provided!", call. = FALSE)
    seed <- sample.int(10000, 1)
    set.seed(seed)
    message("Random seed = ", seed, "\n")} 
  
  #(4) and (5)
  startTime <- Sys.time()#Starting time 
  
  
  
  grid <- create_grid(parameters, nrep) 
  
  if(cores > 1){
    plan(multisession,workers = cores)
  } else{
    plan(sequential)
  }
  suppressMessages(raw_data <- data_generation(simulation, grid))
  
  summary <- summary_function(sum_fun, data_input=raw_data) 
  
  average_over_reps <- average_function(grid_for_avg=create_grid(parameters, 1),
                                        summary, nrep)
  
  comb <- cbind(grid, summary) 
  
  array_1 <- create_array_function(comb, parameters, nrep) 
  
  endTime <- Sys.time()
  
  cpt <- endTime - startTime
  
  #(6)
  summary_1 <- output_function(array_1,
                               average_over_reps,
                               parameters,cores,
                               simulation,nrep,cpt)
  
return(summary_1)
}

```


The tests below present the performance of `main_function()` with the normal distribution.

## Test 1 : Summary performance

```{r, Testing main function}
param_list3x <- list(c("n", 10, 100, 10)
                     ,c("mu", 0, 10, 1)
                     ,c("sd", 0, 5, 1))

test_me <- main_function(parameters=param_list3x
              , nrep = 5
              , simulation = rnorm
              , sum_fun="mean"
              , seed=123 
              , cores=1)

```

All summary components, results, average result and simulation summary are clear.


## Test 2 : Visualization performance

* Visualizing average
```{r,ggplot2}
ggplot(test_me$average,aes(x=avg,y=n))+geom_line()

```

* Visualizing average by using `facet_grid()`
```{r,facet}
ggplot(test_me$average,aes(x=avg))+facet_grid(n~.)+
  geom_density()

```
As given graphs above, the simulation result works well with `ggplot2`-methods.

\pagebreak

# Examples

## Comparing the execution times of OLS and GLS simulations
As an example of Monte Carlo simulation, OLS and GLS coefficients $\beta$ are estimated with and without parallelisation to compare the execution time.
```{r,ols-gls}
ols_f <- function(n,mu,sd){
  e <- rnorm(n,mu,sd)
  x <- runif(n)
  y <- 0.5*x + e
  ols.hat <- t(x) %*% y / t(x)%*%x
  return("ols"=ols.hat)}

gls_f <- function(n,mu,sd){
  e <- rnorm(n,mu,sd)
  x <- runif(n)
  y <- 0.5*x + e
  v.inv <- diag(1/(1:n))
  c <- chol(v.inv)
  cy <- c %*% y
  cx <- c %*% x
  gls_hat <- t(cx) %*% cy / t(cx)%*%cx
  return("gls"=gls_hat)
  
  param_list <- list(c("n",100,1000,100),c("mu",0,1,0.25),c("sd",1,2,.5))
}
```
As shown above, simple OLS and GLS functions are defined to find $\beta$ coefficients. However, the execution time of the GLS  would be much longer than OLS since the Cholesky Decomposition (`chol()`) is applied to  the GLS function.
  
  
  

**OLS simulation without parallel processing:**

```{r , ols}
 param_list <- list(c("n",100,1000,100),c("mu",0,1,0.25),c("sd",1,2,.5))
ols <- main_function(parameters = param_list,
                     nrep=5,
                     simulation = ols_f,
                     sum_fun="mean",
                     seed=123,
                     cores=1)




```


The total execution time of OLS simulation is 1.163067 seconds when one core is used.


**OLS simulation with parallel processing:**

```{r, parallel ols}
ols <- main_function(parameters = param_list,
                     nrep=5,
                     simulation = ols_f,
                     sum_fun="mean",
                     seed=123,
                     cores=4)
```
The total execution time of OLS simulation is 1.163067 seconds when four cores are used.




**GLS with parallel processing:** 
```{r,gls in parallel}
gls <- main_function(parameters = param_list,
                     nrep=5,
                     simulation = gls_f,
                     sum_fun="mean",
                     seed=123,
                     cores=4)

```
The total execution time of GLS simulation is 1.13 seconds when four cores are used.




**GLS without parallel processing:**

```{r,gls}
gls <- main_function(parameters = param_list,
                     nrep=5,
                     simulation = gls_f,
                     sum_fun="mean",
                     seed=123,
                     cores=1)

```
As seen in the summary part, the total execution time of the simulation takes 1.56 seconds which also proves that the parallel process works well. Therefore, the execution times of the simulation might differ on other computers.




## Visualisation 



**Visualizing MSE(Mean Square Error) of OLS and GLS simulations:**


MSE is calculated by `out$average$mse` for each simulation.

```{r}
gls$average <-  gls$average %>% mutate(mse =(2-avg)^2 )
ols$average <-  ols$average %>% mutate(mse =(2-avg)^2 )

ols$average %>% ggplot(aes(x=avg,y=mu,col="OLS"))+
  facet_grid(n~mean(mse))+geom_line()+
 geom_line(data=gls$average,aes(x=avg,y=mu,col="GLS"))+
  scale_color_manual(name = "Estimation",
                     values = c("OLS" = "blue", "GLS" = "red"))

```
\pagebreak


**Density graph of MSE of $\beta$ in OLS and GLS simulations**
```{r}
ggplot(ols$average,aes(x=mse,col="OLS"))+facet_grid(n~.)+
  geom_density()+
  geom_density(data=gls$average,aes(x=avg,col="GLS"))+
  scale_color_manual(name = "Estimation", 
                     values = c("OLS" = "blue", "GLS" = "red"))
```


\pagebreak

# Conclusion

The above section illustrates the power of the implemented model and provides a fairly easy-to-use tool that still allows for various specifications in terms of used parameters, data generation processes and summary functions. Researchers, who use Monte Carlo studies regularly, may save a lot of time using a tool like this in the long run. It also lowers the threshold to run a Monte Carlo simulation for users, who do not have the ability or time to code a complete Monte Carlo simulation, like it was done for this paper.

It was shown, that the code works for many different situations, but there are some limitations, for instance, regarding the number of variables used in the parameter grid or the fact, that only a singular output can be returned by the summary statistic. The functional programming approach applied in this work would easily allow for adjustments, in case the purpose of the program needs to be altered or expanded.


\pagebreak

# Contributions

|   | Alexander Langnau | Öcal Kaptan | Sunyoung Ji |
| :------: | :------: | :------: | :------: |
| Planning | X | X | X |
| `create_grid()` | X | X | 0 |
| `data_generation()`  | X | X | 0 | 
| `summary_function()`  | X | 0 | 0 | 
| `create_array_function()`  | X | 0 | 0 | 
| `average_function()`  | X | 0 | 0 | 
| `output_function()`  | 0 | X | 0 | 
| `main_function()`  | X | X | 0 |
| `ggplot2` part   | 0 | X | 0 | 
| Formatting  | 0 | 0 | X | 
| Writing the report  | X | X | X | 
| Literature research  | 0 | 0 | X | 
| Proof-reading  | X | X | X | 











\pagebreak

# References

Adrian G. Barbu, Song Chun Zhu, "Monte Carlo Methods", Springer Singapore, 2020, pp.1-4, doi:https://doi.org/10.1007/978-981-13-2971-5


Czech, Z. "In Introduction to Parallel Computing", Cambridge University Press, 2017, pp. 1-34, doi:10.1017/9781316795835.002

rdocumentation.org, DataCamp, "cat: Concatenate and Print", url:https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/cat


\pagebreak

# Appendix

## Appendix A

**Output of the OLS simulation**
```{r echo=FALSE}
main_function(parameters = param_list,
                     nrep=5,
                     simulation = ols_f,
                     sum_fun="mean",
                     seed=123,
                     cores=1)
```
\pagebreak

**Output of the OLS simulation with parallelisation**
```{r echo=FALSE}
main_function(parameters = param_list,
                     nrep=5,
                     simulation = ols_f,
                     sum_fun="mean",
                     seed=123,
                     cores=4)
```


## Appendix B

**Output of the GLS simulation without parallelisation**

```{r echo=FALSE}
main_function(parameters = param_list,
                     nrep=5,
                     simulation = gls_f,
                     sum_fun="mean",
                     seed=123,
                     cores=1)
```
\pagebreak

**Output of the GLS simulation with parallelisation**

```{r echo=FALSE}
main_function(parameters = param_list,
                     nrep=5,
                     simulation = gls_f,
                     sum_fun="mean",
                     seed=123,
                     cores=4)
```
\pagebreak
