---
title: "A Functional Approach to (Parallelised) Monte Carlo Simulation"
subtitle: "Advanced R for Econometricians"
type: "Final Project"
author: "Alexander Langnau, Öcal Kaptan, Sunyoung Ji"
discipline: "M.Sc. Econometrics"
date: "today"
studid: "232907, 230914, 229979"
supervisor: "Prof. Dr. Christoph Hanck"
secondsupervisor: "M.Sc. Martin C. Arnold, M.Sc. Jens Klenke"
ssemester: "1"
estdegree_emester: "Summer Term 2022"
deadline: "09. 09. 2022"
output:
  pdf_document:
    keep_tex: yes
    template: template.tex
    fig_caption: yes
    citation_package: biblatex
    number_sections: true
toc: true
lot: true
lof: true
graphics: true
biblio-title: References
fontsize: 11pt
geometry: lmargin=2.5cm,rmargin=2.5cm,tmargin=2.5cm,bmargin=2.5cm
biblio-files: references.bib
classoption: a4paper
language: english
---

<!-- % Template Version 1.2 -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(123)
```

```{r library, include=FALSE}
require(utils)
library(tidyverse)
library(purrr)
library(parallel)
library(furrr)
```

# Introduction


The Monte Carlo method is a simulation method for calculating the probabilistic value of a desired function using random numbers. A repeated pseudo-random number generator estimates sample statistics and 
returns a probability distribution of sample which represents that of parameter[@Barbu_2022]. Monte Carlo methods are combined with programming in modern research and contribute to various studies in statistics, economics, and many other science fields. 
This paper makes a progress on developing a collection of different wrapper functions in order to partially automatize the process of running a Monte Carlo simulation. The main function provides a convenient interface for Monte Carlo simulations and allows users to create a parameter grid and to iterate homogenous function calls over the parameter grid. It also offers informative summary statistics including visualization with ggplot-methods and an option to use a parallelization process by utilizing the `furrr` package.
The paper proceeds as follows: Chapter 2 describes preprocesses to establish the Monte Carlo simulation function. The preprocesses includes functions to create a parameter grid and the respective data points drawn from random variables from an user-defined distribution, along with functions that provide summary statistics. Chapter 3 details??? the main Monte Carlo simulation function which consists of the helper functions introduced in the chapter 2. Chapter 4 presents specific examples for the whole simulation process. Finally, chapter 5 summaries the work presented in this paper.

Each chapter contains a simple example to show the usage of each presented function. The underlying distributions and parameters are vary to demonstrate, that the functions work for different specifications. Possible restrictions will be covered and discussed as well.

# Preprocess: Creating Helper functions

The reprocess comprises 5 helper functions: `create_grid()`, `data_generation()`, `summary_function()`, `create_array_function()`, and `output_function()`. The functions are named in a way, that the underlying purpose is directly clear. These functions are the building blocks of the `main_function()`, which takes the user input and runs the Monte Carlo simulation by itself.

## create_grid()

The first helper function introduced is the `create_grid()`-function, which automatically creates a hyper-parameter grid over all permutations specified by the user. It is one of the functions to improve performance of the main Monte Carlo simulation function. Although a is mainly not known in advance, it is important to find an appropriate range of a parameter to improve performance of  functions.[@Rana_2022].
  
  
```{r create grid}
create_grid <- function(parameters, nrep){
  input <- parameters
  storage <- list()
  name_vec <- c()
  
  for(i in 1:length(input)){ #1:3
    a <- as.numeric(input[[i]][[2]])
    b <- as.numeric(input[[i]][[3]])
    c <- as.numeric(input[[i]][[4]])
    output <- seq(from=a, to=b, by=c)
    storage[[i]] <-  output
    name_vec[i] <- input[[i]][[1]]
  }
  
  grid <- expand_grid(unlist(storage[1])
                      , unlist(storage[2])
                      , unlist(storage[3])
                      , unlist(storage[4])
                      , unlist(storage[5])
                      , c(1:nrep))
  
  names(grid) <- c(name_vec, "rep")
  
  return(grid)
}
```

Users have to input the parameters in a specific format: 

```
parameter_list <- list(c("variable name 1", from, to, by) 
                      ,c("variable name 2", from, to, by)
                      ,c("variable name 3", from, to, by)
                      ,c("variable name 4", from, to, by))
```

`parameter_list` works with a minimum of 1 and a maximum of 4 variables. The structure of arguments is similar to `seq()` in R: Each vector contained in the list needs 4 arguments specified, that is the function name, the start of the sequence, the end of the sequence and the steps, by which the interval gets divided. It would be easy to adapt this helper function for more parameters, but it is assumed, that a grid with up to 4 parameters offers enough complexity for the simulation. The function basically takes the information of the input parameter list and creates a grid with  `tidyr::expand_grid()`. The argument `nrep` specifies how many repetitions per parameter constellation are created, where a seperate row in the parameter grid get created for each repetition.

**`create_grid()` Example:**
```{r example create_grid}

#four parameters 
param_list0 <- list(c("n", 10, 20, 10)
                    ,c("mu", 0, 0.5, 0.25)
                    ,c("sd", 0, 0.3, 0.1)
                    ,c("gender", 0, 1, 1))

head(create_grid(param_list0, nrep=3), n=10)


```





## data_generation()

The second helper function called `data_generation()` takes the arguments `grid` and `simulation` as inputs. `simulation` is the argument for the user defined function for the data generation process, while `grid` is the parameter grid previously created. The user can choose between a variety of probability distributions by entering the name of the function, for example `rnorm` for the normal distribution or `runig` for the uniform distribution

The n data points created for each set of parameters are stored as separate elements in a list, since this format is a very flexible way of storing data. 

`data_generation()` chooses a mapping function itself based on the number of parameters. The table below shows Mapping function, Mapping function for parallelization and the number of parameters that is used in `data_generation()`:

| Map | Map for Parallelization | Number of parameters |
| :------: | :------: | :------: |
| map() | future_map | $n = 1$ |
| map2() | future_map2 | $n = 2$ | 
| pmap | future_pmap | $n \geq 3$ | 

`options = furrr_options(seed = TRUE)` is for reproducible random number generation(RNG) process. This argument takes control of the RNG process for parallelization and generates the same numbers according to the given seed. More details can be found by running the command `?furrr_options` in RStudio.


```{r data generation and parallel process}
data_generation <- function(simulation, grid){
  
  if(ncol(grid)==2){
    var1 <- c(unlist(grid[,1]))
    if(cores>1){
      data <- future_map(var1, simulation,.options = furrr_options(seed = TRUE))
    }else{
      data <- map(var1, simulation)
    }
  }
  
  if(ncol(grid)==3){
    var1 <- c(unlist(grid[,1]))
    var2 <- c(unlist(grid[,2]))
    if(cores>1){
      data <- future_map2(var1, var2, simulation,.options = furrr_options(seed = TRUE))
    } else{
      data <- map2(var1, var2, simulation)
    }
  } 
  
  if(ncol(grid)==4){
    var1 <- c(unlist(grid[,1]))
    var2 <- c(unlist(grid[,2]))
    var3 <- c(unlist(grid[,3]))
    list1 <- list(var1,var2,var3)
    if(cores>1){
      data <- future_pmap(list1, .f=simulation,.options = furrr_options(seed = TRUE))
    }else{
      data <- pmap(list1, .f=simulation)
    }
  }
  
  return(data)
}
```

Monte Carlo simulations can become quickly very demanding in terms of computing time. In that case, Parallel processing is useful. In the parallel processes, each process is executed simultaneously but separately. Interconnections are proceeded through communication chanel[@Czech_2017]


`data_generation()` automatically used the right function from the `furrrr`-package, if the user specified more than 1 core. 

**`data_generation()` Example:**
The example below demonstrates a non-parallel processing function with a Poisson distribution. The time difference between parallel and non-parallel functions will be dealt with in the Chapter 3.

```{r test data_generation()}
cores <- 1
#param_list1 <- list(c("n", 10, 20, 10))

param_list2 <- list(c("n", 10, 20, 10)
                  ,c("lambda", 0.5, 1, 0.5))
#create_grid(param_list1, nrep=10)
#create_grid(param_list1, nrep=1)

'grid1 <- create_grid(param_list1, nrep=3)
tail(data_generation(simulation=rnorm, grid=grid1),1)'

grid2 <- create_grid(param_list2, nrep=1)
sim1 <- data_generation(simulation=rpois, grid=grid2)


names(sim1) <- c("n=10, lamda = 0.5","n=10, lamda = 1",
                 "n=20, lamda = 0.5","n=20, lamda = 1")
grid2
sim1
 
```

`sim1` contains the generated data by `data_generation` with grid2 and poisson distribution as inputs.
The below function shows the application of `data_generation` to uniform and poisson distribution:

```{r, dg application}
# Application to Uniform distribution
param_list_runif <- list(c("n", 10, 30, 10)
                         ,c("min", 0, 0, 0)
                         ,c("max", 1, 1, 0))


grid_unif <- create_grid(param_list_runif, nrep=3)
tail(data_generation(simulation=runif, grid=grid_unif),1)

# Application to Poisson distribution

param_list_rpois <- list(c("n", 10, 30, 10)
                         , c("lambda", 0, 10, 1))

grid_pois <- create_grid(param_list_rpois, nrep=3)
head(grid_pois,2) # nrow(grid_pois) = 99
head(data_generation(simulation=rpois, grid=grid_pois),1)
```

Like explained before, the data  stored in a list, where the data points for each set of parameters are stored under a different variable in the list. The first variable (saved under `$n1`) are based on 10 draws from a uniform distribution with min = 0 and max = 2. Each variable in the list relates to a row in the parameter grid.


## summary_function()


So far, the paper explain the way to create a *raw* data that is distributed as users choose by using `create_grid` and  `data_generation`. Based on the raw data, this chapter introduces `summary_function()` that produces summary statistics that users require.
The function basically extracts the user-defined summary function (`sum_fun`) from the raw data using a `sapply()`-loop. Results are stored in a $(nrow(grid ) * 1)$-dimensional matrix, which is combined with a parameter grid in the next step.


```{r summary_function}

summary_function <- function(sum_fun, data_input){
  
  count <- length(data_input)
  summary_matrix <- matrix(nrow=count, ncol=1)
  
  for(i in 1:count){
    input <- list(data_input[[i]])
    output <- sapply(sum_fun, do.call, input)
    summary_matrix[i] <- output
  }

  colnames(summary_matrix) <- sum_fun
  return(summary_matrix)
}
```

**`summary_function` Example:**
For this example data generated by using normal distribution, with the respective parameters n, $\mu$ and the standard deviation specified in the parameter list. The list containing the raw data using `data_generation()` is stored in the object `test_data`, which is the data input for `summary_function()`. The arithmetic mean, using R´s built in `mean()` - function is used as second input in order to calculate the mean of all the  data points, that were created under a unique set of parameters. This output relates exactly to each row of the used parameter grid. At a later point, these summary statistics get merged with the parameter grid in a data frame.



```{r summary test}
param_list3 <- list(c("n", 10, 20, 10)
                    ,c("mu", 1, 2, 0.25)
                    ,c("sd", 0.5, 1, 0.1))

grid_test <- create_grid(param_list3, nrep=3)
test_data <- data_generation(simulation=rnorm, grid=grid_test)
summary_data <- summary_function(sum_fun=list("mean"), data_input=test_data)
head(summary_data)
nrow(summary_data)
```


## create_array_function()

Even though the example above includes a fairly small range of parameter grid, the simulation returns 180 summaried data points. In `main_function`, the results from the previous step get merged with the parameter grid into one data frame. This way to store the data allows users to apply further data wrangling processes. A multi-dimensional array is more suitable for printing the output in a tidy and clear way. `create_array_function()` takes all relevant data from the previous steps (parameter grid and the results of the Monte Carlo simulation) and transforms it into an array with the correct dimensions. 

```{r, array}
create_array_function <- function(comb, parameters, nrep){
  storage <- list()
  name_vec <- c()
  
  for(i in 1:length(parameters)){ 
    a <- as.numeric(parameters[[i]][[2]])
    b <- as.numeric(parameters[[i]][[3]])
    c <- as.numeric(parameters[[i]][[4]])
    output <- seq(from=a, to=b, by=c)
    storage[[i]] <-  output
    name_vec[i] <- parameters[[i]][[1]] 
  }
  
  
  matrix.numeration <-  paste("rep","=", 1:nrep, sep = "")
  
  if(length(parameters)==1){
    comb_ordered <-  comb %>% arrange(comb[,2])
    seq1 <- c(unlist(storage[1]))
    
    row.names <- paste(name_vec[1],"=",seq1, sep = "")
    
    dimension_array <- c(length(seq1), nrep)
    dim_names_list <- list(row.names, matrix.numeration)
  }
  
  if(length(parameters)==2){
    comb_ordered <-  comb %>% arrange(comb[,2])  %>% arrange(comb[,3])
    seq1 <- c(unlist(storage[1]))
    seq2 <- c(unlist(storage[2]))
    
    row.names <- paste(name_vec[1],"=",seq1, sep = "")
    column.names <-  paste(name_vec[2],"=",seq2, sep = "")
    
    dimension_array <- c(length(seq1), length(seq2), nrep)
    dim_names_list <- list(row.names, column.names, matrix.numeration)
  }
  
  if(length(parameters)==3){
    comb_ordered <-  comb %>% arrange(comb[,2])  %>% 
      arrange(comb[,3]) %>% arrange(comb[,4]) 
    seq1 <- c(unlist(storage[1]))
    seq2 <- c(unlist(storage[2]))
    seq3 <- c(unlist(storage[3]))
    
    row.names <- paste(name_vec[1],"=",seq1, sep = "")
    column.names <-  paste(name_vec[2],"=",seq2, sep = "")
    matrix.names1 <-  paste(name_vec[3],"=",seq3, sep = "")
    
    dimension_array <- c(length(seq1), length(seq2), length(seq3), nrep)
    dim_names_list <- list(row.names, column.names, 
                           matrix.names1, matrix.numeration)
    
  }
  
  
  array1 <- array(comb_ordered[,ncol(comb)] 
                  , dim = dimension_array
                  , dim_names_list)
  return(array1)
}

```

In order to test `create_array_function`, we need to set up an altered version of `main_function`. The `main_function` is discussed in the next chapter. Also, a slightly modified version of the example using the `rnorm()` is used, where the parameter grid spans over a larger sequence.


  

`create_array_function` Example:
```{r, array ex}

# PREP TEST `create_array_function`
main_function_array_test <-  function(parameters #list of parameters
                                      , nrep #number of repetitions
                                      , simulation #data genereation
                                      , sum_fun){ #summary statistics
  
  grid <- create_grid(parameters, nrep) #Step 1: create grid
  raw_data <- data_generation(simulation, grid) #Step 2: simlate data
  summary <- summary_function(sum_fun, data_input=raw_data) #Step 3: Summary statistics
  comb <- cbind(grid, summary) #Step 4: Combine resuluts with parameters
  array_1 <- create_array_function(comb, parameters, nrep) #Step 5: Create array
  
  return(comb)
}





param_list3x <- list(c("n", 10, 60, 10)
                     ,c("mu", 0, 6, 1)
                     ,c("sd", 1, 2, 1))

comb1 <- main_function_array_test(parameters=param_list3x
                                  , nrep = 2
                                  , simulation = rnorm
                                  , sum_fun="mean")

array_test <- create_array_function(comb=comb1, parameters=param_list3x, nrep=2)

array_test
```

Under these specifications, the data was transformed into an 4-dimensional array. Sample size n and the sample mean $\mu$ are the variables  at the side of each row and column. Also, it was specified, that two repetitions are done for each set of parameters, while two values ($\sigma = \{1, 2\}$) were given for the standard deviation. The output contains the correct amount of tables (4). This style of output allows the user to easily oversee a broad variety of different parameter constellation.
Through `create_array_function`, users can obtain all combinations corresponding each grid, the number of repetition, and the summary function that users require, such as `mean` in this case.


## average_function()

The example above used just two repetitions for each parameter constellation, to keep the output simple. In practice, the user would probably repeat the simulations over a higher number of repetitions, which would also drastically increase the size of the array. `average_function()` calculates the average over all repetitions and stores in an array with a dimension, that is reduced by one, since the dimension for repetitions is not relevant anymore.

```{r}

average_function <- function(grid_for_avg, summary, nrep){
  grid_for_avg <- grid_for_avg[-ncol(grid_for_avg)] #remove column for reps
  n_rows <- nrow(grid_for_avg)
  n_col <- ncol(grid_for_avg)
  
  for(i in 1:n_rows){
    start <- 1 + (i-1)*nrep
    end <- i*nrep
    grid_for_avg[i, n_col+1] <- mean(summary[start:end, ])
  }
  
  grid_plus_mc <- data.frame(grid_for_avg)
  
  colnames(grid_plus_mc)[n_col+1] <- "avg"
  
  return(grid_plus_mc)
  
}
```





## output_function()

 `Output_function`  is the last part of preprocess. This function takes results and parameters of Monte Carlo simulation as inputs, as well as, converts them to output format on the console. Thus, users can win the tidy form of summary of simulation.

`array_1`,`average_over_reps`,`parameters`,`cores`,`simulation`,
`nrep`,`cpt`  are used as input parameters in the `output_function`.
`cpt` means execution time for simulation. More detail will be adressed in the next chapter.

When it comes to the structure `output_function`, (1) `out` is an empty list for storing simulation results, averaged results and result summary. (2) `Eco` is the class name of `out`. The class should be assigned to visualize simulation result with ggplot-method. (3) Results from `array_1` and `average_over_reps` are assigned as `out$results` and `out$average` respectively. (4) These results have the classes which is their own names: `out$results` and `out$average`, thereby preventing the future error during visualizing simulation results with ggplot-method. ggplot-method requires specific classes, such as `data.frame`. (5) `cat` is useful for producing output in user-defined functions. It converts its arguments to character vectors, concatenates them to a single character vector, appends the given $`sep` =  string(s)$ to each element and then outputs them[@DataCamp]. (6) The neat output is returned at the end.


```{r echo=TRUE}


output_function <- function(array_1,average_over_reps,parameters,cores,simulation,
                            nrep,cpt){
  # (1)
  out <- list() 
  # (2) 
  class(out) <- "Eco" 
  # (3)
  out$results <- array_1 
  out$average <- average_over_reps 
  # (4)
  class(out$average) <- c("Eco",class(out$average))
  class(out$results) <- c("Eco",class(out$results))
  # (5)
  if(cores>1){
    parallel = "Multisession"
  } else {       
    parallel = "Sequential"
  }
  text <-  cat("\n",
           "Repetition(nrep)      : ",nrep,"\n\n",
           "Parallelization Type  : ",parallel,"\n\n",
           "Number of Cores Used in  Parallelization : ",cores,
           " out of",detectCores(),"\n\n",
           "Input Parameters : ",paste(parameters),"\n\n",
           "Simulation Length :",length(array_1),"\n",
           "Minumum :",min(array_1),"\n",
           "Maximum :",max(array_1),"\n",
           "Mean    :", mean(array_1),"\n",
           "Median  :",median(array_1),"\n\n",
           "Execution Time of Monte Carlo Simulation",
           as.numeric(cpt),"secs \n\n",
           "Name of The Class :",class(out))
  # (6)
  return(out)
}

```
`output_function` represents the output of the main Monte Carlo simulation function in the next chapter.



# Main Function: Monte Carlo simulation function

The `main_function` is built up by the helper functions in chapter 2 and includes additional
arguments to improve a performance of the function. (1) `parameters` is a parameter list, `nrep` is the number of repetitions, simulation is a `data_generation`, `sum_fun` is a summary function that users require, `seed set` is for reproducibility of simulation, and `cores` is the number of cores that exist in the  CPU. (2) `if and else` commands check how many cores are used in the main function and if cores are more than maximum number of the cores or not. By using `detectCores()` in parallel package, maximum number of the cores in the CPU saved in the object `max.cores`. (3) Setting seed is important step to get the same result for randomization. `main_function` either takes seed that users decide or set the random seed when there is no seed provided. `sample.int()` generates a random number and uses it as a seed for reproducibility of the simulation. (4) `Sys.time()` function confirms execution time of the simulation. `startTime` and `endTime` save the starting time and
ending time of the simulation respectively. The difference between them is
the execution time `cpt` which is included in summary statistics as well. (5) `plan()` is used to parallelize simulation. `plan()` has two arguments, “sequential” or “multisession”. “Sequential” runs non-parallel processing with 1 core, on the other hands, users can define the number of cores to use with “Multisession” argument. Lastly, (6) main_function produces a tidy summary statistics with output_function in chaper 2.


```{r}
#(1)
main_function <-  function(parameters 
                           , nrep 
                           , simulation 
                           , sum_fun 
                           ,seed = NULL
                           ,cores=NULL){
 
    
  #(2)
  max.cores <- detectCores()
  if(cores>max.cores){
    stop("Number of Cores cannot be bigger than total number of cores")
  }
  #(3)
  if(!is.null(seed)) {
    set.seed(seed)}
  else {
    warning("No seed provided!", call. = FALSE)
    seed <- sample.int(10000, 1)
    set.seed(seed)
    message("Random seed = ", seed, "\n")} 
  
  #(4) and (5)
  startTime <- Sys.time()#Starting time 
  
  
  
  grid <- create_grid(parameters, nrep) 
  
  if(cores > 1){
    plan(multisession,workers = cores)
  } else{
    plan(sequential)
  }
  suppressMessages(raw_data <- data_generation(simulation, grid))
  
  summary <- summary_function(sum_fun, data_input=raw_data) 
  
  average_over_reps <- average_function(grid_for_avg=create_grid(parameters, 1), summary, nrep)
  
  comb <- cbind(grid, summary) 
  
  array_1 <- create_array_function(comb, parameters, nrep) 
  
  endTime <- Sys.time()
  
  cpt <- endTime - startTime
  
  #(6)
  summary_1 <- output_function(array_1,average_over_reps,parameters,cores,simulation,
                           nrep,cpt)
  
return(summary_1)
}

```


Tests below presents the performance of main_function with normal distribution.

## Test1:Summary Performance

```{r, Testing main function}
param_list3x <- list(c("n", 10, 100, 10)
                     ,c("mu", 0, 10, 1)
                     ,c("sd", 0, 5, 1))

test_me <- main_function(parameters=param_list3x
              , nrep = 5
              , simulation = rnorm
              , sum_fun="mean"
              ,seed=123 
              ,cores=1)

```

All components of summary, results, average result and summary of simulation are clear.


## Test2: Visualization performance

* Visualizing average
```{r,ggplot2}
ggplot(test_me$average,aes(x=avg,y=n))+geom_line()

```

* Visualizing average by using `facet_grid()`
```{r,facet}
ggplot(test_me$average,aes(x=avg))+facet_grid(n~.)+geom_density()

```
As given graphs above, the simulation result works well with ggplot2 methods.

# Examples

As an example to
Monte Carlo Simulation, OLS and GLS coefficients(/beta2) are simulated with/without parallelization to show execution time of the parallel process.
```{r,ols-gls}
ols_f <- function(n,mu,sd){
  e <- rnorm(n,mu,sd)
  x <- runif(n)
  y <- 0.5*x + e
  ols.hat <- t(x) %*% y / t(x)%*%x
  return("ols"=ols.hat)}

gls_f <- function(n,mu,sd){
  e <- rnorm(n,mu,sd)
  x <- runif(n)
  y <- 0.5*x + e
  v.inv <- diag(1/(1:n))
  c <- chol(v.inv)
  cy <- c %*% y
  cx <- c %*% x
  gls_hat <- t(cx) %*% cy / t(cx)%*%cx
  return("gls"=gls_hat)
  
  param_list <- list(c("n",100,1000,100),c("mu",0,1,0.25),c("sd",1,2,.5))
}
```
As shown above, simple OLS and GLS functions are defined to find /beta2 coefficients. The execution time of the GLS function would be much more longer than OLS function, since “The Cholesky Decomposition” is applied to GLS function.


* OLS simulation without parallel processing:  
```{r , ols}
 param_list <- list(c("n",100,1000,100),c("mu",0,1,0.25),c("sd",1,2,.5))
ols <- main_function(parameters = param_list,nrep=5,simulation = ols_f,sum_fun="mean",seed=123,cores=1)
ols
```
Total execution time of OLS simulation is 8.46 seconds when only one core is used


* OLS simulation with parallel processing:

```{r, parallel ols}
ols <- main_function(parameters = param_list,nrep=5,simulation = ols_f,sum_fun="mean",seed=123,cores=4)
ols
```
Total execution time of OLS simulation is 12 seconds when only 4 core is used


* GLS with parallel processing:
```{r,gls in parallel}
gls <- main_function(parameters = param_list,nrep=5,simulation = gls_f,sum_fun="mean",seed=123,cores=4)
gls
```


• GLS without parallel processing:

```{r,gls}
gls <- main_function(parameters = param_list,nrep=5,simulation = gls_f,sum_fun="mean",seed=123,cores=1)
gls
```
As seen as  on the summary part, total execution time of the simulation took 36.35 seconds which also proves that parallel process works well.As a reminder, those simulations ran on MacBook Air 10 with  total 8 cores. Execution times of the simulation might differ on other computers.

* Visualizing MSE(Mean Square Error) in OLS and GLS simulations: MSE is calculated by
`out$average$mse` for each simulation.

```{r}
gls$average <-  gls$average %>% mutate(mse =(2-avg)^2 )
ols$average <-  ols$average %>% mutate(mse =(2-avg)^2 )

ols$average %>% ggplot(aes(x=avg,y=mu,col="OLS"))+
  facet_grid(n~mean(mse))+geom_line()+
 geom_line(data=gls$average,aes(x=avg,y=mu,col="GLS"))+
  scale_color_manual(name = "Estimation", values = c("OLS" = "blue", "GLS" = "red"))

```

* Density of MSE of $ß2$ in OLS and GLS simulations.
```{r}
ggplot(ols$average,aes(x=mse,col="OLS"))+facet_grid(n~.)+geom_density()+
  geom_density(data=gls$average,aes(x=avg,col="GLS"))+
  scale_color_manual(name = "Estimation", values = c("OLS" = "blue", "GLS" = "red"))
```




# Conclusion

The above section illustrates the power of our implemented model and gives the fairly easy 
to use tool, that still allows for a variety of different specifications in terms of used parameters,
data generation processes and summary functions. Researchers, who use Monte Carlo studys on a regular basis, may save a lot of time using a tool like this in the long run.

By nature, there may be cases, where our implementation doesnt satisfy the needs of the user to the fullest, but for a wide variety of examples we showed, that it worked well and served the goal that we aimed for. Our functional programming approach allows for easy and flexible adjustments in case the use of our functions should be expanded, f.e. if a grid of more than 3 (or 4?) parameters is needed.

Theoretically, this work could be implemented as an R package to share it with the R community. But since the `MonteCarlo()` function of the `vigniette` package already provides a well working alternative to our
project besides some minor differences, there is currently no need in doing that.



# References

# Contributions

|   | Alexander Langnau | Öcal Kaptan | Sunyoung Ji |
| :------: | :------: | :------: | :------: |
| Planning | 0 | 0 | 0 |
| Create_grid | 0 | 0 | 0 |
| Data_generation  | 0 | 0 | 0 | 
| Summary_function  | 0 | 0 | 0 | 
| Create_array_function  | 0 | 0 | 0 | 
| Average_function  | 0 | 0 | 0 | 
| Output_function  | 0 | 0 | 0 | 
| ggplot part   | 0 | 0 | 0 | 
| Data_generation  | 0 | 0 | 0 | 
| Formatting  | 0 | 0 | 0 | 
| Writing the report  | 0 | 0 | 0 | 
| Proof-reading  | 0 | 0 | 0 | 











\pagebreak


